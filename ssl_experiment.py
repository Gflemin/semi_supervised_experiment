# -*- coding: utf-8 -*-
"""SSL_Experiment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BQbsh29F5XZkucGaMtjGAaxbCr-Q1VkL
"""

!pip install datasets
# !pip install modAL

from datasets import load_dataset

import pandas as pd
import numpy as np
import seaborn as sns
import random
import time
import warnings

warnings.filterwarnings(action='once')

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import KFold
from sklearn.model_selection import GridSearchCV

from sklearn.metrics import accuracy_score, auc, roc_curve, recall_score

def make_pandas_dataset(dataset, prop_sample=0.2, rand_prop=0, random_state=22):
  # dataset = load_dataset(name)
  train_df = pd.DataFrame(dataset['train'])
  test_df = pd.DataFrame(dataset['test'])

  print(f"train data initial shape {train_df.shape}")

  extra_df = train_df.sample(frac=prop_sample, random_state=random_state)

  train_df = train_df[~train_df.index.isin(extra_df.index)]

  print(f"train data shape {train_df.shape}")
  print(f"test data shape {test_df.shape}")
  print(f"extra data shape {extra_df.shape}")

  train_df = randomize_labels(train_df, rand_prop=rand_prop, random_state=random_state)
  test_df = randomize_labels(test_df, rand_prop=rand_prop, random_state=random_state)
  extra_df = randomize_labels(extra_df, rand_prop=rand_prop, random_state=random_state)

  return train_df, test_df, extra_df


def randomize_labels(df, col='label', rand_prop=0, random_state=22, surpress_msgs=True):
  n = int(df.shape[0] * rand_prop)
  random.seed(random_state)
  idx = random.sample(list(df.index), n)

  zero_df = df[(df.index.isin(idx)) & (df[col] == 0)]
  zero_df[col] = 1
  one_df = df[(df.index.isin(idx)) & (df[col] == 1)]
  one_df[col] = 0

  mod_df = pd.concat([zero_df, one_df])

  df_not_rand = df[~df.index.isin(mod_df.index)]

  result = pd.concat([df_not_rand, mod_df])

  if not surpress_msgs:
    print(f"NOTE: {zero_df.shape[0]} labels randomly switched from 0 to 1")
    print(f"NOTE: {one_df.shape[0]} labels randomly switched from 1 to 0")

  return result


def preprocess_text(train_df, test_df, extra_df, preprocessor,
                    text_col='text', label_col='label'):
  X_train = preprocessor.fit_transform(train_df[text_col])
  X_test = preprocessor.transform(test_df[text_col])
  X_extra = preprocessor.transform(extra_df[text_col])

  y_train = train_df[label_col]
  y_test = test_df[label_col]
  y_extra = extra_df[label_col]

  print(X_train.shape, X_test.shape, X_extra.shape,
        y_train.shape, y_test.shape, y_extra.shape)

  return X_train, X_test, X_extra, y_train, y_test, y_extra


def score_unanimous_approval(candidate_model, model_name, all_models, model_thresholds,
                             X_train, y_train, X_test, y_test, X_extra, y_extra,
                             rand_prop, refit_prop, random_state=22):

  # fit check
  assert hasattr(candidate_model, 'classes_')
  assert isinstance(all_models, dict)
  for model in all_models:
    assert hasattr(model, 'classes_')

  assert isinstance(model_thresholds, dict)

  n_sample = int(refit_prop * X_train.shape[0])

  random.seed(random_state)
  sample_idx = random.sample(list(range(X_extra.shape[0])), n_sample)

  X_sampled = X_extra[sample_idx, :]
  y_sampled = y_extra.loc[sample_idx]

  print(f"NOTE: {n_sample} rows sampled from extra (proportion {refit_prop} of {X_train.shape[0]} original train size) and added to train")

  pred_dict = {}
  for key, value in all_models.items():
    intermed = value.predict_proba(X_sampled)
    pred = np.where(intermed < model_thresholds[key], 0, 1)
    pred_dict[str(key+'_pred')] = pred

  result = pd.DataFrame(pred_dict)

  return result

# def fit_and_score(model, model_name, X_train, y_train, X_test, y_test,
#                   rand_prop=0, refit_prop=0, random_state=22):
#   # models = {'logistic_reg':LogisticRegression(), 'multinom_nb':MultinomialNB(),
#   #       'rand_forest':RandomForestClassifier(), 'boost_trees':GradientBoostingClassifier(),
#   #       'boost_trees_tuned':GradientBoostingClassifier(learning_rate=0.08, n_estimators=150,
#   #                                                       max_depth=4)}
#   # model = models[model_name]
#   model.fit(X_train, y_train)

#   metric_frame = roc_metric_frame(model, model_name, X_test, y_test,
#                                   rand_prop=rand_prop, refit_prop=refit_prop)

#   return metric_frame, model


def roc_metric_frame(model, model_name, X_test, y_test, rand_prop, refit_prop):
  pred = model.predict_proba(X_test)[:,1]

  thresholds = np.arange(0, 1.01, 0.01)

  fpr_scores = []
  tpr_scores = []
  utility_scores = []
  for thresh in thresholds:
    pred_class = np.where(pred < thresh, 0, 1)
    fpr = 1 - recall_score(y_test, pred_class, pos_label=0)
    tpr = recall_score(y_test, pred_class, pos_label = 1)
    utility = tpr - fpr

    fpr_scores.append(fpr)
    tpr_scores.append(tpr)
    utility_scores.append(utility)

  metric_frame = pd.DataFrame({'model_name':model_name,
                               'rand_prop':rand_prop,
                               'refit_prop':refit_prop,
                               'threshold':thresholds,
                               'fpr':fpr_scores,
                               'tpr':tpr_scores,
                               'utility':utility_scores})


  return metric_frame

"""# Load raw data and create an "extra set"
"""

# Imdb
imdb_dataset = load_dataset('imdb')
raw_train, raw_test, raw_extra = make_pandas_dataset(imdb_dataset, prop_sample=0.2,
                                                     rand_prop=0.05, random_state=22)

raw_extra

preprocessor = TfidfVectorizer(ngram_range = (1,3), max_df = 0.5, min_df = 50)

X_train, X_test, X_extra, y_train, y_test, y_extra = preprocess_text(raw_train, raw_test, raw_extra,
                preprocessor=preprocessor)

metrics = []
models = {'logistic_reg':LogisticRegression(), 'multinom_nb':MultinomialNB()}
for key, value in models.items():
  models[key] = value.fit(X_train, y_train)
  metric_df = roc_metric_frame(value, key, X_test, y_test,
                               rand_prop=0.05, refit_prop=0)
  # roc_metric_frame(model, model_name, X_test, y_test, rand_prop, refit_prop):
  metrics.append(metric_df)

metrics_concat = pd.concat(metrics).reset_index(drop=True)
metrics_concat['method'] = 'default'
metrics_concat

best_threshes = {}
for key, _ in models.items():
  best_thresh = metrics_concat[metrics_concat['model_name']==key].sort_values('utility', ascending=False)['threshold'].iloc[0]
  best_threshes[key] = best_thresh

best_threshes

import copy
# models = {'logistic_reg':LogisticRegression(), 'multinom_nb':MultinomialNB()}
# models_big = {'logistic_reg':LogisticRegression(), 'multinom_nb':MultinomialNB(),
#           'rand_forest':RandomForestClassifier(n_jobs=2)}
# for key, value in models_big.items():
#   models_big[key] = value.fit(X_train, y_train)
# for key, value in models.items():
#   models[key] = value.fit(X_train, y_train)
res = score_unanimous_approval(candidate_model='logistic_reg',
                                  all_models=models,
                                  model_thresholds=best_threshes,
                                  X_train=X_train, y_train=y_train,
                                  X_test=X_test, y_test=y_test,
                                  X_extra=X_extra, y_extra=y_extra,
                                  rand_prop=0.05, refit_prop=0.2,
                                  random_state=22)

res

check = pd.concat([metrics_concat, res])

check

sns.relplot(check, x='fpr', y='tpr', hue='model_name', col='method', kind='line')

check.sort_values('utility', ascending=False).iloc[0:20]

# TODO: need to do more testing for benefits of this in low data regimes

pd.concat([a,b],axis=0)

import scipy

scipy.sparse.vstack([a,b])

r[3,]

lr = LogisticRegression().fit(X_train,y_train)

# lr.fit(X_test,y_test)

def score_unanimous_approval(candidate_model, all_models, model_thresholds, X_train, y_train, X_test, y_test, X_extra, y_extra,
                             rand_prop, refit_prop, random_state=22):

  # checks
  assert isinstance(all_models, dict)
  for key, value in all_models.items():
    assert hasattr(value, 'classes_')
  assert isinstance(model_thresholds, dict)

  # define fx method
  method = 'score_unanimous_approval'

  n_sample = int(refit_prop * X_train.shape[0])

  random.seed(random_state)
  sample_idx = random.sample(list(range(X_extra.shape[0])), n_sample)

  X_sampled = X_extra[sample_idx, :]
  y_sampled = y_extra.iloc[sample_idx]

  print(f"NOTE: {n_sample} rows sampled from extra (proportion {refit_prop} of {X_train.shape[0]} original train size) and added to train")

  all_models_internal = copy.deepcopy(all_models)

  pred_dict = {}
  for key, value in all_models_internal.items():
    intermed = value.predict_proba(X_sampled)[:,1]
    pred = np.where(intermed < model_thresholds[key], 0, 1)
    pred_dict[str(key+'_pred')] = pred

  result = pd.DataFrame(pred_dict)

  print('pred_dict made')

  result['unanim_one'] = np.apply_along_axis(all, axis=1, arr = result.values == 1)
  result['unanim_zero'] = np.apply_along_axis(all, axis=1, arr = result.values == 0)

  conds = [(result['unanim_zero']==True) & (result['unanim_one']==False),
           (result['unanim_zero']==False) & (result['unanim_one']==True),
           (result['unanim_zero']==False) & (result['unanim_one']==False)]
  choices = [0, 1, np.nan]
  result['label'] = np.select(conds, choices, np.nan)

  result = result.dropna()

  print('na dropped')

  add_idx = result.index
  X_sampled = X_sampled[add_idx, :]
  y_sampled = y_sampled.iloc[add_idx]

  X_train_new = scipy.sparse.vstack([X_train, X_sampled])
  y_train_new = pd.concat([y_train, y_sampled], axis=0)

  metric_frames = []
  for key, value in all_models_internal.items():
    fit_mod = value.fit(X_train_new, y_train_new)
    all_models_internal[key] = fit_mod
    metric_frame = roc_metric_frame(fit_mod, key, X_test, y_test,
                     rand_prop=rand_prop, refit_prop=refit_prop)
    metric_frame['method'] = method
    metric_frames.append(metric_frame)

  result = pd.concat(metric_frames)

  return result

# Yelp
raw_yelp_train_big, raw_yelp_test_big, raw_yelp_extra_big = make_pandas_dataset("yelp_polarity")
raw_yelp_train = raw_yelp_train_big.sample(frac=0.1, random_state=22)
raw_yelp_test = raw_yelp_test_big.sample(20000, random_state=22)
raw_yelp_extra = raw_yelp_extra_big.sample(5000, random_state=22)

print(raw_yelp_train.shape, raw_yelp_test.shape, raw_yelp_extra.shape)

"""# Randomize data labels

Only randomize a set proportion of train and extra examples. Leave test untouched!
"""

prop_list = [0.05, 0.2]

raw_imdb_train_05 = randomize_labels(raw_imdb_train, rand_prop=prop_list[0])
raw_imdb_test_05 = randomize_labels(raw_imdb_test, rand_prop=prop_list[0])
raw_imdb_extra_05 = randomize_labels(raw_imdb_extra, rand_prop=prop_list[0])
raw_yelp_train_05 = randomize_labels(raw_yelp_train, rand_prop=prop_list[0])
raw_yelp_test_05 = randomize_labels(raw_yelp_test, rand_prop=prop_list[0])
raw_yelp_extra_05 = randomize_labels(raw_yelp_extra, rand_prop=prop_list[0])

raw_imdb_train_20 = randomize_labels(raw_imdb_train, rand_prop=prop_list[1])
raw_imdb_test_20 = randomize_labels(raw_imdb_test, rand_prop=prop_list[1])
raw_imdb_extra_20 = randomize_labels(raw_imdb_extra, rand_prop=prop_list[1])
raw_yelp_train_20 = randomize_labels(raw_yelp_train, rand_prop=prop_list[1])
raw_yelp_test_20 = randomize_labels(raw_yelp_test, rand_prop=prop_list[1])
raw_yelp_extra_20 = randomize_labels(raw_yelp_extra, rand_prop=prop_list[1])

"""# Finish data preprocessing"""

raw_imdb_train_05

preprocessor = TfidfVectorizer(ngram_range = (1,3), max_df = 0.5, min_df = 50)

X_train_i_05, X_test_i_05, X_extra_i_05, y_train_i_05, y_test_i_05, y_extra_i_05 = preprocess_text(raw_imdb_train_05, raw_imdb_test_05, raw_imdb_extra_20,
                preprocessor=preprocessor)

X_train_i_20, X_test_i_20, X_extra_i_20, y_train_i_20, y_test_i_20, y_extra_i_20 = preprocess_text(raw_imdb_train_20, raw_imdb_test_20, raw_imdb_extra_20,
                preprocessor=preprocessor)

preprocessor2 = TfidfVectorizer(ngram_range = (1,3), max_df = 0.5, min_df = 50)

X_train_y_05, X_test_y_05, X_extra_y_05, y_train_y_05, y_test_y_05, y_extra_y_05 = preprocess_text(raw_yelp_train_05, raw_yelp_test_05, raw_yelp_extra_05,
                preprocessor=preprocessor2)
X_train_y_20, X_test_y_20, X_extra_y_20, y_train_y_20, y_test_y_20, y_extra_y_20 = preprocess_text(raw_yelp_train_20, raw_yelp_test_20, raw_yelp_extra_20,
                preprocessor=preprocessor2)

"""# Very naive SSL technique #1: Unanimous Approval Voting

"""

models = {'logistic_reg':LogisticRegression(), 'multinom_nb':MultinomialNB()}
models_big = {'logistic_reg':LogisticRegression(), 'multinom_nb':MultinomialNB(),
          'rand_forest':RandomForestClassifier(n_jobs=2)}
for key, value in models_big.items():
  models_big[key] = value.fit(X_train_i_05, y_train_i_05)
for key, value in models.items():
  models[key] = value.fit(X_train_i, y_train_i)
  result = score_unanimous_approval(value, key, all_models, model_thresholds,
                                    X_train=X_train_i_05, y_train=y_train_i_05,
                                    X_test=X_test_i_05, y_test=y_test_i_05,
                                    X_extra=X_extra_i, y_extra=y_extra_i,
                                    rand_prop=0.05, refit_prop=0.05, random_state=22)

models = {'logistic_reg':LogisticRegression(), 'multinom_nb':MultinomialNB()}
models_big = {'logistic_reg':LogisticRegression(), 'multinom_nb':MultinomialNB(),
          'rand_forest':RandomForestClassifier(n_jobs=2)}

for key, value in models.items():
  models[key] = value.fit(X_train_y, y_train_y)

best_threshes = {}
for key, value in models.items():
  metric_frame = roc_metric_frame(model, model_name=key, X_test=X_test_y, y_test=y_test_y, rand_prop=0.05, refit_prop=0.02)
  best_thresh = metric_frame.sort_values('utility', ascending=False)['threshold'].iloc[0]
  best_threshes[key] = best_thresh

best_threshes
# def get_best_thresholds(models):

a

"""# Very naive SSL technique #2: Best Model Labelling"""

def fit_best_approval(model, model_name, X_train, y_train, X_test, y_test, X_extra, y_extra,
                      rand_prop, refit_prop, random_state=22):
  models = {'logistic_reg':LogisticRegression(), 'multinom_nb':MultinomialNB(),
          'rand_forest':RandomForestClassifier(), 'boost_trees':GradientBoostingClassifier(),
          'boost_trees_tuned':GradientBoostingClassifier(learning_rate=0.08, n_estimators=150,
                                                         max_depth=4)}

  n_sample = int(refit_prop * X_train.shape[0])

  random.seed(random_state)
  sample_idx = random.sample(list(range(X_extra.shape[0])), n_sample)

  X_sampled = X_extra[sample_idx, :]
  y_sampled = y_extra.loc[sample_idx]

  X_train_more = np.concatenate([X_train, X_sampled], axis=0)
  y_train_more = pd.concat([y_train, y_sampled], axis=0).reset_index(drop=True) # NOTE: X/y indices broken here

  print(f"NOTE: {n_sample} rows sampled from extra (proportion {refit_prop} of {X_train.shape[0]} original train size) and added to train")

  model = models[model_name]
  model.fit(X_train_more, y_train_more)

  metric_frame = roc_metric_frame(model, model_name, X_test, y_test,
                                  rand_prop=rand_prop, refit_prop=refit_prop)

  return metric_frame, model

"""# Random Sample + Fit"""

def more_data_refit(model, model_name, incorr_prop, refit_prop, X_train, y_train, X_test, y_test, X_extra, y_extra, random_state=22):
  models = {'logistic_reg':LogisticRegression(), 'multinom_nb':MultinomialNB(),
          'rand_forest':RandomForestClassifier(), 'boost_trees':GradientBoostingClassifier(),
          'boost_trees_tuned':GradientBoostingClassifier(learning_rate=0.08, n_estimators=150,
                                                         max_depth=4)}

  n_sample = int(refit_prop * X_train.shape[0])

  random.seed(random_state)
  sample_idx = random.sample(list(range(X_extra.shape[0])), n_sample)

  X_sampled = X_extra[sample_idx, :]
  y_sampled = y_extra.loc[sample_idx]

  X_train_more = np.concatenate([X_train, X_sampled], axis=0)
  y_train_more = pd.concat([y_train, y_sampled], axis=0).reset_index(drop=True) # NOTE: X/y indices broken here

  print(f"NOTE: {n_sample} rows sampled from extra (prop {prop} of {X_train.shape[0]} original train size) and added to train")

  model = models[model_name]
  model.fit(X_train_more, y_train_more)

  metric_frame = roc_metric_frame(model, model_name, X_test, y_test)

  return metric_frame, model

"""# Hyperparameter Tuning

def fit_and_score(model
"""

def fit_and_score(model, model_name, X_train, y_train, X_test, y_test, X_extra, y_extra, random_state=22):
  models = {'logistic_reg':LogisticRegression(), 'multinom_nb':MultinomialNB(),
        'rand_forest':RandomForestClassifier(), 'boost_trees':GradientBoostingClassifier(),
        'boost_trees_tuned':GradientBoostingClassifier(learning_rate=0.08, n_estimators=150,
                                                        max_depth=4)}
  model = models[model_name]
  model.fit(X_train, y_train)

  metric_frame = roc_metric_frame(model, model_name, X_test, y_test)

  return metric_frame, model

model[key]

models = {'logistic_reg':LogisticRegression(), 'multinom_nb':MultinomialNB(),
        'rand_forest':RandomForestClassifier(), 'boost_trees':GradientBoostingClassifier(),
        'boost_trees_tuned':GradientBoostingClassifier(learning_rate=0.08, n_estimators=150,
                                                        max_depth=4)}
del models['boost_trees_tuned']


for model in models:
  model.fit(X_train_y, y_train_y)
  pred = model.predict_proba(X_extra_y)[,1]

  # opt thresholds
  thresholds = np.arange(0, 1.01, 0.01)

"""# Very naive SSL technique #2: Best Model Labelling"""